{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Data cleaning\n",
    "\n",
    "Before doing actual data analysis, we usually first need to clean the data. \n",
    "This might involve steps such as dealing with missing values and encoding categorical variables as integers.\n",
    "In this exercise, you will perform such steps based on the Titanic passenger data.\n",
    "\n",
    "1. Load the Titanic data set in `titanic.csv` located in the `data/` folder.\n",
    "2. Report the number of observations with missing `Age`, for example using [`isna()`](https://pandas.pydata.org/docs/reference/api/pandas.isna.html).\n",
    "3. Compute the average age in the data set. Use the following approaches and compare your results:\n",
    "    1.  Use pandas's [`mean()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html) method.\n",
    "    2.  Convert the `Age` column to a NumPy array using [`to_numpy()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html). Experiment with NumPy's [`np.mean()`](https://numpy.org/doc/2.0/reference/generated/numpy.mean.html) and [`np.nanmean()`](https://numpy.org/doc/2.0/reference/generated/numpy.nanmean.html) to see if you obtain the same results.\n",
    "4. Replace the all missing ages with the mean age you computed above, rounded to the nearest integer.\n",
    "   Note that in \"real\" applications, replacing missing values with sample means is usually not a good idea.\n",
    "5. Convert this updated `Age` column to integer type using [`astype()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html).\n",
    "6. Generate a new column `Female` which takes on the value one if `Sex` is equal to `\"female\"` and zero otherwise. \n",
    "   This is called an _indicator_ or _dummy_ variable, and is preferrable to storing such categorical data as strings.\n",
    "   Delete the original column `Sex`.\n",
    "7. Save your cleaned data set as `titanic-clean.csv` using [`to_csv()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) with `,` as the field separator.\n",
    "   Tell `to_csv()` to *not* write the `DataFrame` index to the CSV file as it's not needed in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2                                Heikkinen, Miss Laina  female  26.0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4                             Allen, Mr. William Henry    male  35.0   \n",
       "..                                                 ...     ...   ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0   \n",
       "887                        Graham, Miss Margaret Edith  female  19.0   \n",
       "888            Johnston, Miss Catherine Helen \"Carrie\"  female   NaN   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "               Ticket     Fare Cabin Embarked  \n",
       "0           A/5 21171   7.2500   NaN        S  \n",
       "1            PC 17599  71.2833   C85        C  \n",
       "2    STON/O2. 3101282   7.9250   NaN        S  \n",
       "3              113803  53.1000  C123        S  \n",
       "4              373450   8.0500   NaN        S  \n",
       "..                ...      ...   ...      ...  \n",
       "886            211536  13.0000   NaN        S  \n",
       "887            112053  30.0000   B42        S  \n",
       "888        W./C. 6607  23.4500   NaN        S  \n",
       "889            111369  30.0000  C148        C  \n",
       "890            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#Path to the data folder\n",
    "DATA_PATH = '../../data'\n",
    "filename= f'{DATA_PATH}/titanic.csv'\n",
    "df=pd.read_csv(filename,sep=',')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   Ticket       891 non-null    object \n",
      " 7   Fare         891 non-null    float64\n",
      " 8   Cabin        204 non-null    object \n",
      " 9   Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 69.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(177)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 2\n",
    "df['Age'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(29.69911764705882)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 3\n",
    "df['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.  , 38.  , 26.  , 35.  , 35.  ,   nan, 54.  ,  2.  , 27.  ,\n",
       "       14.  ,  4.  , 58.  , 20.  , 39.  , 14.  , 55.  ,  2.  ,   nan,\n",
       "       31.  ,   nan, 35.  , 34.  , 15.  , 28.  ,  8.  , 38.  ,   nan,\n",
       "       19.  ,   nan,   nan, 40.  ,   nan,   nan, 66.  , 28.  , 42.  ,\n",
       "         nan, 21.  , 18.  , 14.  , 40.  , 27.  ,   nan,  3.  , 19.  ,\n",
       "         nan,   nan,   nan,   nan, 18.  ,  7.  , 21.  , 49.  , 29.  ,\n",
       "       65.  ,   nan, 21.  , 28.5 ,  5.  , 11.  , 22.  , 38.  , 45.  ,\n",
       "        4.  ,   nan,   nan, 29.  , 19.  , 17.  , 26.  , 32.  , 16.  ,\n",
       "       21.  , 26.  , 32.  , 25.  ,   nan,   nan,  0.83, 30.  , 22.  ,\n",
       "       29.  ,   nan, 28.  , 17.  , 33.  , 16.  ,   nan, 23.  , 24.  ,\n",
       "       29.  , 20.  , 46.  , 26.  , 59.  ,   nan, 71.  , 23.  , 34.  ,\n",
       "       34.  , 28.  ,   nan, 21.  , 33.  , 37.  , 28.  , 21.  ,   nan,\n",
       "       38.  ,   nan, 47.  , 14.5 , 22.  , 20.  , 17.  , 21.  , 70.5 ,\n",
       "       29.  , 24.  ,  2.  , 21.  ,   nan, 32.5 , 32.5 , 54.  , 12.  ,\n",
       "         nan, 24.  ,   nan, 45.  , 33.  , 20.  , 47.  , 29.  , 25.  ,\n",
       "       23.  , 19.  , 37.  , 16.  , 24.  ,   nan, 22.  , 24.  , 19.  ,\n",
       "       18.  , 19.  , 27.  ,  9.  , 36.5 , 42.  , 51.  , 22.  , 55.5 ,\n",
       "       40.5 ,   nan, 51.  , 16.  , 30.  ,   nan,   nan, 44.  , 40.  ,\n",
       "       26.  , 17.  ,  1.  ,  9.  ,   nan, 45.  ,   nan, 28.  , 61.  ,\n",
       "        4.  ,  1.  , 21.  , 56.  , 18.  ,   nan, 50.  , 30.  , 36.  ,\n",
       "         nan,   nan,  9.  ,  1.  ,  4.  ,   nan,   nan, 45.  , 40.  ,\n",
       "       36.  , 32.  , 19.  , 19.  ,  3.  , 44.  , 58.  ,   nan, 42.  ,\n",
       "         nan, 24.  , 28.  ,   nan, 34.  , 45.5 , 18.  ,  2.  , 32.  ,\n",
       "       26.  , 16.  , 40.  , 24.  , 35.  , 22.  , 30.  ,   nan, 31.  ,\n",
       "       27.  , 42.  , 32.  , 30.  , 16.  , 27.  , 51.  ,   nan, 38.  ,\n",
       "       22.  , 19.  , 20.5 , 18.  ,   nan, 35.  , 29.  , 59.  ,  5.  ,\n",
       "       24.  ,   nan, 44.  ,  8.  , 19.  , 33.  ,   nan,   nan, 29.  ,\n",
       "       22.  , 30.  , 44.  , 25.  , 24.  , 37.  , 54.  ,   nan, 29.  ,\n",
       "       62.  , 30.  , 41.  , 29.  ,   nan, 30.  , 35.  , 50.  ,   nan,\n",
       "        3.  , 52.  , 40.  ,   nan, 36.  , 16.  , 25.  , 58.  , 35.  ,\n",
       "         nan, 25.  , 41.  , 37.  ,   nan, 63.  , 45.  ,   nan,  7.  ,\n",
       "       35.  , 65.  , 28.  , 16.  , 19.  ,   nan, 33.  , 30.  , 22.  ,\n",
       "       42.  , 22.  , 26.  , 19.  , 36.  , 24.  , 24.  ,   nan, 23.5 ,\n",
       "        2.  ,   nan, 50.  ,   nan,   nan, 19.  ,   nan,   nan,  0.92,\n",
       "         nan, 17.  , 30.  , 30.  , 24.  , 18.  , 26.  , 28.  , 43.  ,\n",
       "       26.  , 24.  , 54.  , 31.  , 40.  , 22.  , 27.  , 30.  , 22.  ,\n",
       "         nan, 36.  , 61.  , 36.  , 31.  , 16.  ,   nan, 45.5 , 38.  ,\n",
       "       16.  ,   nan,   nan, 29.  , 41.  , 45.  , 45.  ,  2.  , 24.  ,\n",
       "       28.  , 25.  , 36.  , 24.  , 40.  ,   nan,  3.  , 42.  , 23.  ,\n",
       "         nan, 15.  , 25.  ,   nan, 28.  , 22.  , 38.  ,   nan,   nan,\n",
       "       40.  , 29.  , 45.  , 35.  ,   nan, 30.  , 60.  ,   nan,   nan,\n",
       "       24.  , 25.  , 18.  , 19.  , 22.  ,  3.  ,   nan, 22.  , 27.  ,\n",
       "       20.  , 19.  , 42.  ,  1.  , 32.  , 35.  ,   nan, 18.  ,  1.  ,\n",
       "       36.  ,   nan, 17.  , 36.  , 21.  , 28.  , 23.  , 24.  , 22.  ,\n",
       "       31.  , 46.  , 23.  , 28.  , 39.  , 26.  , 21.  , 28.  , 20.  ,\n",
       "       34.  , 51.  ,  3.  , 21.  ,   nan,   nan,   nan, 33.  ,   nan,\n",
       "       44.  ,   nan, 34.  , 18.  , 30.  , 10.  ,   nan, 21.  , 29.  ,\n",
       "       28.  , 18.  ,   nan, 28.  , 19.  ,   nan, 32.  , 28.  ,   nan,\n",
       "       42.  , 17.  , 50.  , 14.  , 21.  , 24.  , 64.  , 31.  , 45.  ,\n",
       "       20.  , 25.  , 28.  ,   nan,  4.  , 13.  , 34.  ,  5.  , 52.  ,\n",
       "       36.  ,   nan, 30.  , 49.  ,   nan, 29.  , 65.  ,   nan, 50.  ,\n",
       "         nan, 48.  , 34.  , 47.  , 48.  ,   nan, 38.  ,   nan, 56.  ,\n",
       "         nan,  0.75,   nan, 38.  , 33.  , 23.  , 22.  ,   nan, 34.  ,\n",
       "       29.  , 22.  ,  2.  ,  9.  ,   nan, 50.  , 63.  , 25.  ,   nan,\n",
       "       35.  , 58.  , 30.  ,  9.  ,   nan, 21.  , 55.  , 71.  , 21.  ,\n",
       "         nan, 54.  ,   nan, 25.  , 24.  , 17.  , 21.  ,   nan, 37.  ,\n",
       "       16.  , 18.  , 33.  ,   nan, 28.  , 26.  , 29.  ,   nan, 36.  ,\n",
       "       54.  , 24.  , 47.  , 34.  ,   nan, 36.  , 32.  , 30.  , 22.  ,\n",
       "         nan, 44.  ,   nan, 40.5 , 50.  ,   nan, 39.  , 23.  ,  2.  ,\n",
       "         nan, 17.  ,   nan, 30.  ,  7.  , 45.  , 30.  ,   nan, 22.  ,\n",
       "       36.  ,  9.  , 11.  , 32.  , 50.  , 64.  , 19.  ,   nan, 33.  ,\n",
       "        8.  , 17.  , 27.  ,   nan, 22.  , 22.  , 62.  , 48.  ,   nan,\n",
       "       39.  , 36.  ,   nan, 40.  , 28.  ,   nan,   nan, 24.  , 19.  ,\n",
       "       29.  ,   nan, 32.  , 62.  , 53.  , 36.  ,   nan, 16.  , 19.  ,\n",
       "       34.  , 39.  ,   nan, 32.  , 25.  , 39.  , 54.  , 36.  ,   nan,\n",
       "       18.  , 47.  , 60.  , 22.  ,   nan, 35.  , 52.  , 47.  ,   nan,\n",
       "       37.  , 36.  ,   nan, 49.  ,   nan, 49.  , 24.  ,   nan,   nan,\n",
       "       44.  , 35.  , 36.  , 30.  , 27.  , 22.  , 40.  , 39.  ,   nan,\n",
       "         nan,   nan, 35.  , 24.  , 34.  , 26.  ,  4.  , 26.  , 27.  ,\n",
       "       42.  , 20.  , 21.  , 21.  , 61.  , 57.  , 21.  , 26.  ,   nan,\n",
       "       80.  , 51.  , 32.  ,   nan,  9.  , 28.  , 32.  , 31.  , 41.  ,\n",
       "         nan, 20.  , 24.  ,  2.  ,   nan,  0.75, 48.  , 19.  , 56.  ,\n",
       "         nan, 23.  ,   nan, 18.  , 21.  ,   nan, 18.  , 24.  ,   nan,\n",
       "       32.  , 23.  , 58.  , 50.  , 40.  , 47.  , 36.  , 20.  , 32.  ,\n",
       "       25.  ,   nan, 43.  ,   nan, 40.  , 31.  , 70.  , 31.  ,   nan,\n",
       "       18.  , 24.5 , 18.  , 43.  , 36.  ,   nan, 27.  , 20.  , 14.  ,\n",
       "       60.  , 25.  , 14.  , 19.  , 18.  , 15.  , 31.  ,  4.  ,   nan,\n",
       "       25.  , 60.  , 52.  , 44.  ,   nan, 49.  , 42.  , 18.  , 35.  ,\n",
       "       18.  , 25.  , 26.  , 39.  , 45.  , 42.  , 22.  ,   nan, 24.  ,\n",
       "         nan, 48.  , 29.  , 52.  , 19.  , 38.  , 27.  ,   nan, 33.  ,\n",
       "        6.  , 17.  , 34.  , 50.  , 27.  , 20.  , 30.  ,   nan, 25.  ,\n",
       "       25.  , 29.  , 11.  ,   nan, 23.  , 23.  , 28.5 , 48.  , 35.  ,\n",
       "         nan,   nan,   nan, 36.  , 21.  , 24.  , 31.  , 70.  , 16.  ,\n",
       "       30.  , 19.  , 31.  ,  4.  ,  6.  , 33.  , 23.  , 48.  ,  0.67,\n",
       "       28.  , 18.  , 34.  , 33.  ,   nan, 41.  , 20.  , 36.  , 16.  ,\n",
       "       51.  ,   nan, 30.5 ,   nan, 32.  , 24.  , 48.  , 57.  ,   nan,\n",
       "       54.  , 18.  ,   nan,  5.  ,   nan, 43.  , 13.  , 17.  , 29.  ,\n",
       "         nan, 25.  , 25.  , 18.  ,  8.  ,  1.  , 46.  ,   nan, 16.  ,\n",
       "         nan,   nan, 25.  , 39.  , 49.  , 31.  , 30.  , 30.  , 34.  ,\n",
       "       31.  , 11.  ,  0.42, 27.  , 31.  , 39.  , 18.  , 39.  , 33.  ,\n",
       "       26.  , 39.  , 35.  ,  6.  , 30.5 ,   nan, 23.  , 31.  , 43.  ,\n",
       "       10.  , 52.  , 27.  , 38.  , 27.  ,  2.  ,   nan,   nan,  1.  ,\n",
       "         nan, 62.  , 15.  ,  0.83,   nan, 23.  , 18.  , 39.  , 21.  ,\n",
       "         nan, 32.  ,   nan, 20.  , 16.  , 30.  , 34.5 , 17.  , 42.  ,\n",
       "         nan, 35.  , 28.  ,   nan,  4.  , 74.  ,  9.  , 16.  , 44.  ,\n",
       "       18.  , 45.  , 51.  , 24.  ,   nan, 41.  , 21.  , 48.  ,   nan,\n",
       "       24.  , 42.  , 27.  , 31.  ,   nan,  4.  , 26.  , 47.  , 33.  ,\n",
       "       47.  , 28.  , 15.  , 20.  , 19.  ,   nan, 56.  , 25.  , 33.  ,\n",
       "       22.  , 28.  , 25.  , 39.  , 27.  , 19.  ,   nan, 26.  , 32.  ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 3\n",
    "df['Age'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(nan)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#part 3\n",
    "np.mean(df['Age'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(29.69911764705882)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#part 3\n",
    "np.nanmean(df['Age'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      22.000000\n",
       "1      38.000000\n",
       "2      26.000000\n",
       "3      35.000000\n",
       "4      35.000000\n",
       "         ...    \n",
       "886    27.000000\n",
       "887    19.000000\n",
       "888    29.699118\n",
       "889    26.000000\n",
       "890    32.000000\n",
       "Name: Age, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#part 4 and 5\n",
    "df['Age'].fillna(value=np.nanmean(df['Age'].to_numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age']=df['Age'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIntCastingNaNError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mAge\u001b[39m\u001b[33m'\u001b[39m]= \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAge\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\generic.py:6662\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6656\u001b[39m     results = [\n\u001b[32m   6657\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6658\u001b[39m     ]\n\u001b[32m   6660\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6661\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6662\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6663\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6664\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    428\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:784\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    782\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    788\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:101\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.ensure_string_array(\n\u001b[32m     97\u001b[39m         arr, skipna=skipna, convert_na_value=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     98\u001b[39m     ).reshape(shape)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m np.issubdtype(arr.dtype, np.floating) \u001b[38;5;129;01mand\u001b[39;00m dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lib.is_np_dtype(dtype, \u001b[33m\"\u001b[39m\u001b[33mM\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:145\u001b[39m, in \u001b[36m_astype_float_to_int_nansafe\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(values).all():\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[32m    146\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    147\u001b[39m     )\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype.kind == \u001b[33m\"\u001b[39m\u001b[33mu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    149\u001b[39m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values >= \u001b[32m0\u001b[39m).all():\n",
      "\u001b[31mIntCastingNaNError\u001b[39m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "df['Age']= df['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sex'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Sex'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#part 6\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mFemale\u001b[39m\u001b[33m\"\u001b[39m] = (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSex\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[33m\"\u001b[39m\u001b[33mfemale\u001b[39m\u001b[33m\"\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;66;03m#replace the column\u001b[39;00m\n\u001b[32m      3\u001b[39m df.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mSex\u001b[39m\u001b[33m\"\u001b[39m])\u001b[38;5;66;03m#delete the original column \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Sex'"
     ]
    }
   ],
   "source": [
    "#part 6\n",
    "df[\"Female\"] = (df[\"Sex\"] == \"female\").astype(int)#replace the column\n",
    "df.drop(columns=[\"Sex\"])#delete the original column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss Laina</td>\n",
       "      <td>26</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>27</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss Margaret Edith</td>\n",
       "      <td>19</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss Catherine Helen \"Carrie\"</td>\n",
       "      <td>30</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>26</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>32</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name  Age            Ticket  \\\n",
       "0                              Braund, Mr. Owen Harris   22         A/5 21171   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...   38          PC 17599   \n",
       "2                                Heikkinen, Miss Laina   26  STON/O2. 3101282   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)   35            113803   \n",
       "4                             Allen, Mr. William Henry   35            373450   \n",
       "..                                                 ...  ...               ...   \n",
       "886                              Montvila, Rev. Juozas   27            211536   \n",
       "887                        Graham, Miss Margaret Edith   19            112053   \n",
       "888            Johnston, Miss Catherine Helen \"Carrie\"   30        W./C. 6607   \n",
       "889                              Behr, Mr. Karl Howell   26            111369   \n",
       "890                                Dooley, Mr. Patrick   32            370376   \n",
       "\n",
       "        Fare Cabin Embarked  Female  \n",
       "0     7.2500   NaN        S       0  \n",
       "1    71.2833   C85        C       1  \n",
       "2     7.9250   NaN        S       1  \n",
       "3    53.1000  C123        S       1  \n",
       "4     8.0500   NaN        S       0  \n",
       "..       ...   ...      ...     ...  \n",
       "886  13.0000   NaN        S       0  \n",
       "887  30.0000   B42        S       1  \n",
       "888  23.4500   NaN        S       1  \n",
       "889  30.0000  C148        C       0  \n",
       "890   7.7500   NaN        Q       0  \n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 2, 1.\n",
    "filename= f'{DATA_PATH}/FRED/FRED_annual.xlsx'\n",
    "df= pd.read_excel(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Year', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>CPI</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>INFLATION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>3500.3</td>\n",
       "      <td>29.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.369863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>3590.1</td>\n",
       "      <td>29.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.013514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>3810.1</td>\n",
       "      <td>30.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.337793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>3976.1</td>\n",
       "      <td>30.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.990099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>4205.3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.307190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>4478.6</td>\n",
       "      <td>31.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>4773.9</td>\n",
       "      <td>32.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.174603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>4904.9</td>\n",
       "      <td>33.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>5145.9</td>\n",
       "      <td>34.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.191617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>5306.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.459770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GDP   CPI  UNRATE  FEDFUNDS  INFLATION\n",
       "Year                                           \n",
       "1960  3500.3  29.6     5.5       3.2   1.369863\n",
       "1961  3590.1  29.9     6.7       2.0   1.013514\n",
       "1962  3810.1  30.3     5.6       2.7   1.337793\n",
       "1963  3976.1  30.6     5.6       3.2   0.990099\n",
       "1964  4205.3  31.0     5.2       3.5   1.307190\n",
       "1965  4478.6  31.5     4.5       4.1   1.612903\n",
       "1966  4773.9  32.5     3.8       5.1   3.174603\n",
       "1967  4904.9  33.4     3.8       4.2   2.769231\n",
       "1968  5145.9  34.8     3.6       5.7   4.191617\n",
       "1969  5306.6  36.7     3.5       8.2   5.459770"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1960:1969]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise 2: Selecting subsets of data\n",
    "\n",
    "In this exercise, you are asked to select subsets of macroeconomic data for the United States based on some criteria.\n",
    "\n",
    "1.  Load the annual data from FRED which are located in `FRED_annual.xlsx` \n",
    "    in the `data/FRED` folder.\n",
    "\n",
    "2.  Print the list of columns and the number of non-missing observations.\n",
    "\n",
    "3.  Since we are dealing with time series data, set the column `Year` as the DataFrame index.\n",
    "\n",
    "4.  Print all observations for the 1960s decade using at least two different methods.\n",
    "\n",
    "5.  Using the data in the column `GDP`, compute the annual GDP growth in percent and store it in the column `GDP_growth`. Select the years in which\n",
    "\n",
    "    1.  GDP growth was above 5%.\n",
    "    2.  GDP growth was negative, but inflation as still above 5% (such episodes are called \"stagflation\" since usually negative GDP growth is associated with low inflation).\n",
    "        \n",
    "        Use at least two methods to select such years.\n",
    "\n",
    "    *Hint:* You can compute changes relative to the previous observation using the \n",
    "    [`pct_change()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html) method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise 3: Labor market statistics for the US\n",
    "\n",
    "In this exercise, you are asked to compute some descriptive statistics for the unemployment rate \n",
    "and the labor force participation (the fraction of the working-age population in the labor force, i.e., individuals who are either employed or unemployed) for the United States.\n",
    "\n",
    "1.  Load the monthly time series from FRED which are located in `FRED_monthly.csv` \n",
    "    in the `data/FRED` folder.\n",
    "\n",
    "    *Hint:* You can use `pd.read_csv(..., parse_dates=['DATE'])` to automatically\n",
    "    parse strings stored in the `DATE` column as dates.\n",
    "\n",
    "2.  Print the list of columns and the number of non-missing observations.\n",
    "\n",
    "3.  Since we are dealing with time series data, set the column `DATE` as the DataFrame index. Using the date index, select all observations from the first three months\n",
    "    of the year 2020.\n",
    "\n",
    "4.  For the columns `UNRATE` (unemployment rate) and `LFPART` (labor force participation), compute and report \n",
    "    the mean, minimum and maximum values for the whole sample. Round your results \n",
    "    to one decimal digit.\n",
    "\n",
    "    *Hint:* You can use the DataFrame methods \n",
    "    [`mean()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html),\n",
    "    [`min()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.min.html), and \n",
    "    [`max()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html)\n",
    "    to compute the desired statistics.\n",
    "\n",
    "    *Hint:* You can use the DataFrame method\n",
    "    [`round()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.round.html)\n",
    "    to truncate the number of decimal digits.\n",
    "\n",
    "5.  You are interested in how the average unemployment rate evolved over the last \n",
    "    few decades. \n",
    "\n",
    "    -   Add a new column `Decade` to the DataFrame which contains the \n",
    "        starting year for each decade (e.g., this value should be 1950\n",
    "        for the years 1950-1959, and so on).\n",
    "\n",
    "        *Hint:* The decade can be computed from the column `Year` using \n",
    "        truncated integer division:\n",
    "        ```python\n",
    "        df['Year'] // 10 * 10\n",
    "        ```\n",
    "\n",
    "    -   Write a loop to compute and report the average unemployment rate (column `UNRATE`) \n",
    "        for each decade.\n",
    "\n",
    "        Include only the decades from 1950 to 2010 for which you have all\n",
    "        observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise 4: Working with string data (advanced)\n",
    "\n",
    "Most of the data we deal with contain strings, i.e., text data (names, addresses, etc.). Often, such data is not in the format needed for analysis, and we have to perform additional string manipulation to extract the exact data we need. This can be achieved using the pandas [string methods](https://pandas.pydata.org/docs/user_guide/text.html#string-methods).\n",
    "\n",
    "To illustrate, we use the Titanic data set for this exercise.\n",
    "\n",
    "1.  Load the Titanic data and restrict the sample to men. (This simplifies the task. Women in this data set have much more complicated names as they contain both their husband's and their maiden name)\n",
    "2.  Print the first five observations of the `Name` column. As you can see, the data is stored in the format _\"Last name, Title First name\"_ where title is something like Mr., Rev., etc.\n",
    "3. Split the `Name` column by `,` to extract the last name and the remainder as separate columns. You can achieve this using the [`partition()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.partition.html#pandas.Series.str.partition) string method.\n",
    "4. Split the remainder (containing the title and first name) using the space character `\" \"` as separator to obtain individual columns for the title and the first name.\n",
    "5. Store the three data series in the original `DataFrame` (using the column names `FirstName`, `LastName` and `Title`) and delete the `Name` column which is no longer needed.\n",
    "6. Finally, extract the ship deck from the values in `Cabin`. The ship deck is the first character in the string stored in `Cabin` (A, B, C, ...). You extract the first character using the \n",
    "[`get()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get.html#pandas.Series.str.get) string method. Store the result in the column `Deck`.\n",
    "\n",
    "*Hint*: Pandas's string methods can be accessed using the `.str` attribute. For example, to partition values in the column `Name`, you need to use\n",
    "```python\n",
    "df['Name'].str.partition()\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECH2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
